# -*- coding: utf-8 -*-
"""
Helper Functions for Snowflake Connectivity and
other snowflake operations.
"""

import sys
import os
import re
import pandas as pd
import snowflake.connector
import configparser
import ast
import json
import logging
import datetime
import numpy as np

curr_timestamp = datetime.datetime.now().strftime("%Y%m%d_%I%M%S")
logname = 'snowflake' + curr_timestamp + '.log'
logger = logging.getLogger("snowflake")
logger.setLevel(logging.INFO)
fh = logging.FileHandler('/var/log/spark-logs/'+logname)
fh.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s  %(levelname)s  %(message)s', datefmt='%Y-%m-%dT%H:%M:%S%z')
fh.setFormatter(formatter)
logger.addHandler(fh)

def update_env_variable():
    """
    Update Environment Variable as per /etc/profile
    """
    with open(r'/etc/profile', 'r') as f:
        profile = f.read()

    pattern = re.compile(r'^export\s*(.*)\s*=\s*(.*)', re.MULTILINE)
    os.environ.update(dict(pattern.findall(profile)))

def dbconfig_parser(region):
    """
    Config parser reading db credentials INI file
    """
    config = configparser.RawConfigParser()
    config.read('/etc/vault-aws-ec2/db_config.ini')
    region = region.lower()
    db_credentials = dict((k.upper(), v) for k, v in config.items(region))
    db_credentials = ast.literal_eval(json.dumps(db_credentials))
    return db_credentials


def get_snowflake_connection(region, db_credentials):
    """authenticate to snowflake and deliver a connection object"""
    # get connection
    ctx = snowflake.connector.connect(
        user=db_credentials['USER'],
        password=db_credentials['PASSWORD'],
        account=db_credentials['HOST'],
        warehouse=db_credentials['WAREHOUSE']
    )
    return ctx

def get_snowflake_cursor(region, db_credentials):
    """deliver a cursor for executing queries"""
    ctx = get_snowflake_connection(region, db_credentials)
    cs = ctx.cursor()
    return cs

def create_sf_table(region, data, tbl_nm=''):
    """
    Create table in Snowflake for given data.

    Args:
        region: AWS region
        data: [Pandas Dataframe | Columns (List/ Tuple) | Query (String) ].
        If Pandas Dataframe, the DDL information will be extracted from to
        create the table.
        tbl_nm: The Table name (database and schema included is preferred)
    """
    # GET SNOWFLAKE CURSOR
    db_credentials = dbconfig_parser(region)
    sf_cur = get_snowflake_cursor(region, db_credentials)

    if isinstance(data, pd.DataFrame):
     # EXTRACT DDL INFORMATION FROM PANDAS
        pd_df = data

        if 'newline' in pd_df.columns:
            pd_df = pd_df.drop('newline', axis=1)

        pd_sf_dtype_map = {'object':'VARCHAR', 'int64':'NUMBER', 'float64':'DECIMAL', 'datetime64':'DATETIME', 'bool':'BOOLEAN'}
        dtype_pattern = re.compile(r'\s+(.*)')
        dtype_str = str(pd_df.dtypes)
        dtype_list = dtype_str.split('\n')
        sf_dtype = list(map(lambda x: pd_sf_dtype_map[dtype_pattern.findall(x)[0]], dtype_list))
        columns = tuple(map(lambda x: ' '.join(x), zip(pd_df.columns, sf_dtype)))

        query = '''CREATE TABLE IF NOT EXISTS {0} ({1})'''.format(tbl_nm, ','.join(columns))

    elif isinstance(data, (list, tuple)):
        columns = data

        query = '''CREATE TABLE IF NOT EXISTS {0} ({1})'''.format(tbl_nm, ','.join(columns))

    elif isinstance(data, str):
        query = data

    else:
        print('INVALID DATA TYPE {0} PROVIDED TO CREATE THE TABLE.'.format(type(data)))
        raise Exception()

    # RUN QUERY
    sf_cur.execute(query)
    print('Table Created Successfully.')


def select_table(user, table, cursor):
    """select and return a specificied user table"""
    sql = '''SELECT * from SB.user_{user}.{table}'''
    cursor.execute(sql)
    return cursor.fetchall()

def get_table_as_df(user, table, cursor):
    """deliver a pandas dataframe of a selected user table"""
    t_data = select_table(user, table, cursor)
    t_columns = cursor._column_idx_to_name.values()
    df = pd.DataFrame(t_data, columns=t_columns)
    return df

def get_query_as_df(sql, cursor):
    """deliver a pandas dataframe for a given query
    Example input:
    sql = "SELECT * FROM db.pcdw.t2_evt WHERE evt_Dt = '2017-12-31' LIMIT 2" """
    cursor.execute(sql)
    t_data = cursor.fetchall()
    t_columns = cursor._column_idx_to_name.values()
    df = pd.DataFrame(t_data, columns=t_columns)
    for col in df.columns:
        if (df[col].dtypes != np.int64) & (df[col].dtypes != np.float64):
            df[col] = df[col].fillna('')
    return df

def unloadmain(region, query):
    try:
        db_credentials = dbconfig_parser(region)
        logger.info('Extract Database connection details')
    except Exception as err:
        logger.error('Extract Database connection details failed: %s', err)
        exit(2)
    else:
        logger.info('Start database session')
    try:
        unload_data = get_query_as_df(query, get_snowflake_cursor(region, db_credentials))
        logger.info('Data Unload : %s', query)
    except Exception as e:
        logger.error('Database unload failed: %s', e)
        exit(3)
    else:
        logger.info('Database unload finished successfully for : %s', query)

    fh.flush()
    fh.close()
    return unload_data
